{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        self.locationCondition = {'A': '0', 'B': '0'}\n",
    "\n",
    "        self.locationCondition['A'] = random.randint(0, 1)\n",
    "        self.locationCondition['B'] = random.randint(0, 1)\n",
    "\n",
    "\n",
    "class SimpleReflexVacuumAgent(Environment):\n",
    "    def __init__(self, Environment):\n",
    "        print(Environment.locationCondition)\n",
    "        Score = 0\n",
    "        vacuumLocation = random.randint(0, 1)\n",
    "        if vacuumLocation == 0:\n",
    "            print(\"Vacuum is randomly placed at Location A\")\n",
    "            if Environment.locationCondition['A'] == 1:\n",
    "                print(\"Location A is Dirty. \")\n",
    "                Environment.locationCondition['A'] = 0;\n",
    "                Score += 1\n",
    "                print(\"Location A has been Cleaned. :D\")\n",
    "\n",
    "                if Environment.locationCondition['B'] == 1:\n",
    "                    print(\"Location B is Dirty.\")\n",
    "                    print(\"Moving to Location B...\")\n",
    "                    Score -= 1\n",
    "                    Environment.locationCondition['B'] = 0;\n",
    "                    Score += 1\n",
    "                    print(\"Location B has been Cleaned :D.\")\n",
    "            else:\n",
    "                \n",
    "                if Environment.locationCondition['B'] == 1:\n",
    "                    print(\"Location B is Dirty.\")\n",
    "                    Score -= 1\n",
    "                    print(\"Moving to Location B...\")\n",
    "                    Environment.locationCondition['B'] = 0;\n",
    "                    Score += 1\n",
    "                    print(\"Location B has been Cleaned. :D\")\n",
    "\n",
    "        elif vacuumLocation == 1:\n",
    "            print(\"Vacuum is randomly placed at Location B. \")\n",
    "            if Environment.locationCondition['B'] == 1:\n",
    "                print(\"Location B is Dirty\")\n",
    "                Environment.locationCondition['B'] = 0;\n",
    "                Score += 1\n",
    "                print(\"Location B has been Cleaned\")\n",
    "                if Environment.locationCondition['A'] == 1:\n",
    "                    print(\"Location A is Dirty\")\n",
    "                    Score -= 1\n",
    "                    print(\"Moving to Location A\")\n",
    "                    Environment.locationCondition['A'] = 0;\n",
    "                    Score += 1\n",
    "                    print(\"Location A has been Cleaned\")\n",
    "            else:\n",
    "\n",
    "                if Environment.locationCondition['A'] == 1:\n",
    "                    print(\"Location A is Dirty\")\n",
    "                    print(\"Moving to Location A\")\n",
    "                    Score -= 1\n",
    "                    Environment.locationCondition['A'] = 0;\n",
    "                    Score += 1\n",
    "                    print(\"Location A has been Cleaned\")\n",
    "        print(Environment.locationCondition)\n",
    "        print(\"Performance Measurement: \" + str(Score))\n",
    "\n",
    "\n",
    "theEnvironment = Environment()\n",
    "theVacuum = SimpleReflexVacuumAgent(theEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc424502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "example_word= \"I want to tokenize this sentence\"\n",
    "word_token=word_tokenize(example_word)\n",
    "word_token\n",
    "\n",
    "example_sentence=\"Hello Rozan! This is a tutorial on Sentence Tokenization\"\n",
    "sent_token=sent_tokenize(example_sentence)\n",
    "sent_token\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "example_sentence1=\"an apple a day keeps the doctor far away.\"\n",
    "stop_words=set(stopwords.words('english'))\n",
    "word_tokens=word_tokenize(example_sentence1)\n",
    "filter_sentence=[]\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filter_sentence.append(w)\n",
    "print(filter_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "# Define Training DATA i.e, AND Gate Inputs\n",
    "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "output = np.array([[0],[0],[0],[1]])\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(input, output, nb_epoch=600, verbose=2)\n",
    "\n",
    "# Validation\n",
    "print(\"Round off Values: \\n\",model.predict(input).round())\n",
    "print(\"Actual Values: \\n\",model.predict(input))\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "# Define Training DATA i.e, Or Gate Inputs\n",
    "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "output = np.array([[0],[1],[1],[1]])\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(input, output, nb_epoch=300, verbose=2)\n",
    "\n",
    "print(\"Round off Values: \\n\",model.predict(input).round())\n",
    "print(\"Actual Values: \\n\",model.predict(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86406c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer()\n",
    "ps=PorterStemmer()\n",
    "example_text=\"Playing Ludo is a funny activity\"\n",
    "words=word_tokenize(example_text)\n",
    "words\n",
    "for w in words:\n",
    "    print(ps.stem(w))\n",
    "    \n",
    "    \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"feet\"))\n",
    "print(lemmatizer.lemmatize(\"loving\",'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "example_text2=\"An apple a day keeps the doctor far away\"\n",
    "word_token=word_tokenize(example_text2)\n",
    "pos_tagged=nltk.pos_tag(word_token)\n",
    "pos_tagged\n",
    "\n",
    "named_entity_sen=\"Nelson was the president of Africa\"\n",
    "token=word_tokenize(named_entity_sen)\n",
    "taggedtoken=nltk.pos_tag(token)\n",
    "named_entity=nltk.ne_chunk(taggedtoken)\n",
    "named_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77898c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.list = []\n",
    "\n",
    "    def push(self, item):\n",
    "        \"\"\"Push 'item' onto the stack.\"\"\"\n",
    "        self.list.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"Pop the most recently pushed item from the stack.\"\"\"\n",
    "        return self.list.pop()\n",
    "\n",
    "    def top(self):\n",
    "        \"\"\"Return the last element.\"\"\"\n",
    "        return self.list[-1]\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\"Returns true if the stack is empty.\"\"\"\n",
    "        return len(self.list) == 0\n",
    "\n",
    "\n",
    "def depth_first_search(graph, start):\n",
    "    stack = Stack()\n",
    "    stack.push(start)\n",
    "    path = []\n",
    "\n",
    "    while not stack.is_empty():\n",
    "        vertex = stack.pop()\n",
    "        if vertex in path:\n",
    "            continue\n",
    "        path.append(vertex)\n",
    "        for neighbor in graph[vertex]:\n",
    "            stack.push(neighbor)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def main():\n",
    "    adjacency_matrix = {\n",
    "        1: [2, 3],\n",
    "        2: [4, 5],\n",
    "        3: [5],\n",
    "        4: [6],\n",
    "        5: [6],\n",
    "        6: [7],\n",
    "        7: []\n",
    "    }\n",
    "    dfs_path = depth_first_search(adjacency_matrix, 1)\n",
    "    print(dfs_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56463c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features and label variables\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "\n",
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "wheather_encoded=le.fit_transform(wheather)\n",
    "print wheather_encoded\n",
    "\n",
    "# Converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)\n",
    "print \"Temp:\",temp_encoded\n",
    "print \"Play:\",label\n",
    "\n",
    "\n",
    "#Combinig weather and temp into single listof tuples\n",
    "features=zip(weather_encoded,temp_encoded)\n",
    "print features\n",
    "\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print \"Predicted Value:\", predicted\n",
    "\n",
    "#output 1 indicates that the player can play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# calculate a random number where:  a <= rand < b\n",
    "def rand(a, b):\n",
    "    return (b-a)*random.random() + a\n",
    "\n",
    "# Make a matrix (we could use NumPy to speed this up)\n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    m = []\n",
    "    for i in range(I):\n",
    "        m.append([fill]*J)\n",
    "    return m\n",
    "\n",
    "# our sigmoid function, tanh is a little nicer than the standard 1/(1+e^-x)\n",
    "def sigmoid(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "# derivative of our sigmoid function, in terms of the output (i.e. y)\n",
    "def dsigmoid(y):\n",
    "    return 1.0 - y**2\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1 # +1 for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "        \n",
    "        # create weights\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "        # set them to random vaules\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.2, 0.2)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-2.0, 2.0)\n",
    "\n",
    "        # last change in weights for momentum   \n",
    "        self.ci = makeMatrix(self.ni, self.nh)\n",
    "        self.co = makeMatrix(self.nh, self.no)\n",
    "\n",
    "    def update(self, inputs):\n",
    "        if len(inputs) != self.ni-1:\n",
    "            raise ValueError('wrong number of inputs')\n",
    "\n",
    "        # input activations\n",
    "        for i in range(self.ni-1):\n",
    "            #self.ai[i] = sigmoid(inputs[i])\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # hidden activations\n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "\n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "\n",
    "        return self.ao[:]\n",
    "\n",
    "\n",
    "    def backPropagate(self, targets, N, M):\n",
    "        if len(targets) != self.no:\n",
    "            raise ValueError('wrong number of target values')\n",
    "\n",
    "        # calculate error terms for output\n",
    "        output_deltas = [0.0] * self.no\n",
    "        for k in range(self.no):\n",
    "            error = targets[k]-self.ao[k]\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        # calculate error terms for hidden\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "                #print N*change, M*self.co[j][k]\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "        return error\n",
    "\n",
    "\n",
    "    def test(self, patterns):\n",
    "        for p in patterns:\n",
    "            print(p[0], '->', self.update(p[0]))\n",
    "\n",
    "    def weights(self):\n",
    "        print('Input weights:')\n",
    "        for i in range(self.ni):\n",
    "            print(self.wi[i])\n",
    "        print()\n",
    "        print('Output weights:')\n",
    "        for j in range(self.nh):\n",
    "            print(self.wo[j])\n",
    "\n",
    "    def train(self, patterns, iterations=1000, N=0.5, M=0.1):\n",
    "        # N: learning rate\n",
    "        # M: momentum factor\n",
    "        for i in range(iterations):\n",
    "            error = 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.update(inputs)\n",
    "                error = error + self.backPropagate(targets, N, M)\n",
    "            if i % 100 == 0:\n",
    "                print('error %-.5f' % error)\n",
    "\n",
    "\n",
    "def demo():\n",
    "    # Teach network XOR function\n",
    "    pat = [\n",
    "        [[0,0], [0]],\n",
    "        [[0,1], [1]],\n",
    "        [[1,0], [1]],\n",
    "        [[1,1], [0]]\n",
    "    ]\n",
    "\n",
    "    # create a network with two input, two hidden, and one output nodes\n",
    "    n = NN(2, 2, 1)\n",
    "    # train it with some patterns\n",
    "    n.train(pat)\n",
    "    # test it\n",
    "    n.test(pat)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa678db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "  'A' : ['B','C'],\n",
    "  'B' : ['D', 'E'],\n",
    "  'C' : ['F'],\n",
    "  'D' : [],\n",
    "  'E' : ['F'],\n",
    "  'F' : []\n",
    "}\n",
    "\n",
    "visited = [] # List to keep track of visited nodes.\n",
    "queue = []     #Initialize a queue\n",
    "\n",
    "def bfs(visited, graph, node):\n",
    "  visited.append(node)\n",
    "  queue.append(node)\n",
    "\n",
    "  while queue:\n",
    "    s = queue.pop(0) \n",
    "    print (s, end = \" \") \n",
    "\n",
    "    for neighbour in graph[s]:\n",
    "      if neighbour not in visited:\n",
    "        visited.append(neighbour)\n",
    "        queue.append(neighbour)\n",
    "\n",
    "# Driver Code\n",
    "bfs(visited, graph, 'A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
